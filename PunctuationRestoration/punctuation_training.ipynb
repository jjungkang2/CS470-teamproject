{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "punctuatior_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTYvR6-aj1ah"
      },
      "source": [
        "# Before you run this training code:\n",
        "\n",
        "1. Connect to your google drive\n",
        "2. Inside your drive root path, put the 'input' directory constructed in the last step.\n",
        "  (or the ones we provided to you in github repositoy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHEjLFUBEuBW",
        "outputId": "6ed4bd01-3191-4f6e-b132-db8db96d2e2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "root = '/gdrive/My Drive/Punctuator'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI3n9laYE3Iy"
      },
      "source": [
        "import pickle\n",
        "with open (root + '/input/word_dict', 'rb') as file:\n",
        "        word_dict = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEcIdoF5E6x",
        "outputId": "747d76a4-3f8a-4876-c660-6fc0f33b1740"
      },
      "source": [
        "\"\"\"\n",
        "making embedding matrix from pre-trained GloVe.\n",
        "If it is already made, (we provided you in github repository), do not run this code.\n",
        "Since it downloads the full GloVe embedding vector, it will take some time.\n",
        "If you do not run this code, instead, run the code below, to get the pre-made embedding matrix.\n",
        "Also, for model running in the local computer, you should move the resulting embedding matrix to the local directory.\n",
        "\"\"\"\n",
        "from torchtext.vocab import GloVe\n",
        "embedding_glove = GloVe(name = '6B', dim = 100)\n",
        "\n",
        "def get_embedding_matrix(word_dictionary, embedding_dictionary):\n",
        "    dim = embedding_dictionary['the'].size(0)\n",
        "    embedding_matrix = np.zeros((len(word_dictionary), embedding_dictionary['the'].size(0)))\n",
        "    for word in word_dictionary:\n",
        "        num = word_dictionary[word]\n",
        "        embedding_matrix[num] = embedding_dictionary[word]\n",
        "    embedding_matrix[0] = embedding_dictionary['pad']\n",
        "    embedding_matrix[1] = embedding_dictionary['unk']\n",
        "    return embedding_matrix\n",
        "\n",
        "emb_matrix = get_embedding_matrix(word_dict, embedding_glove)\n",
        "\n",
        "with open(root + '/input/GloVe_matrix', 'rb') as file:\n",
        "  emb_matrix = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                          \n",
            " 99%|█████████▉| 397727/400000 [00:16<00:00, 24893.85it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFnpG9-BynY_"
      },
      "source": [
        "\"\"\"\n",
        "This is for downloading a pre-made embedding matrix.\n",
        "Run this code instead of the upper one.\n",
        "\"\"\"\n",
        "with open(root + '/input/GloVe_matrix', 'wb') as file:\n",
        "  pickle.dump(emb_matrix, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRNSttNuHac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18a387f-fd93-4e8b-ebe0-71b21c38fee8"
      },
      "source": [
        "vocab_size = emb_matrix.shape[0]\n",
        "vector_size = emb_matrix.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11176\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCPttmqcHlla"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm.notebook as tq\n",
        "from pathlib import Path\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX7VvL2xHq_O"
      },
      "source": [
        "from easydict import EasyDict as edict\n",
        "\n",
        "# Hyperparameters\n",
        "args = edict()\n",
        "args.batch_size = 32\n",
        "args.lr = 0.001\n",
        "args.epochs = 20\n",
        "args.clip = 1\n",
        "args.ninp = vector_size\n",
        "\n",
        "args.dropout = 0.2\n",
        "\n",
        "args.nlayers = 2\n",
        "args.nhid = 512\n",
        "args.nhead = 8\n",
        "args.attn_pdrop = 0.1   #0.1\n",
        "args.resid_pdrop = 0.1  #0.1\n",
        "args.embd_pdrop = 0.1   #0.1\n",
        "args.nff = 4 * args.nhid\n",
        "\n",
        "args.gpu = True\n",
        "\n",
        "# Basic settings\n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "device = 'cuda:0' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "# Create directory name.\n",
        "result_dir = Path(root) / 'results'\n",
        "result_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKohZxcaHr0j"
      },
      "source": [
        "import pickle\n",
        "\n",
        "class PuncDataset(Dataset): \n",
        "    \"\"\"Punctuation restoration dataset\"\"\"\n",
        "    def __init__(self, data_file_path, train):\n",
        "\n",
        "        if train:\n",
        "            data_path = data_file_path + 'train'\n",
        "        else:\n",
        "            data_path = data_file_path + 'test'\n",
        "\n",
        "        with open (data_path + '_input_small', 'rb') as file:\n",
        "                input = pickle.load(file)\n",
        "                self.input = torch.tensor(input, dtype = torch.long)\n",
        "\n",
        "        with open (data_path + '_output', 'rb') as file:\n",
        "                output = pickle.load(file)\n",
        "                self.punc = torch.tensor(output)\n",
        "        \"\"\"\n",
        "        with open (data_path + '_raw_input', 'rb') as file:\n",
        "                raw_input = pickle.load(file)\n",
        "                #raw_input = np.array(raw_input).T\n",
        "                self.raw_input = raw_input\n",
        "        \"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {'input': self.input[idx], 'punc': self.punc[idx]} #'raw_input' : self.raw_input[idx]\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_awpmu0tHu4s",
        "outputId": "18fb7284-c2e9-48e7-a047-d91013b3b6bb"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "path_to_dir = root + '/input/'\n",
        "\n",
        "# training / validation dataset (spliced into 8:2 ratio)\n",
        "dataset = PuncDataset(path_to_dir, True)\n",
        "total_data_length = len(dataset)\n",
        "train_dataset, valid_dataset = random_split(dataset, [round(total_data_length * 0.8), round(total_data_length * 0.2)])\n",
        "\n",
        "print(len(dataset))\n",
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))\n",
        "\n",
        "#test dataset\n",
        "test_dataset = PuncDataset(path_to_dir, False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle = True, drop_last = True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = args.batch_size, shuffle = False, drop_last = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle = False, drop_last = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29295\n",
            "23436\n",
            "5859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Uunm_6HzuM"
      },
      "source": [
        "trg_ntoken = 6 \n",
        "pad_id = 0\n",
        "src_ntoken = vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYHgLQJPH33I"
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_input = nn.Linear(input_size, 4 * hidden_size)\n",
        "        self.linear_hidden = nn.Linear(hidden_size, 4 * hidden_size)\n",
        "\n",
        "    def forward(self, x, state):\n",
        "        hx, cx = state\n",
        "        hx_out = self.linear_hidden(hx)\n",
        "        x_out = self.linear_input(x)\n",
        "        before_chunk = x_out + hx_out\n",
        "\n",
        "        chunk_forgetgate, chunk_ingate, chunk_cellgate, chunk_outgate = torch.chunk(before_chunk,chunks=4, dim=1)\n",
        "        fx = torch.sigmoid(chunk_forgetgate)\n",
        "        ix = torch.sigmoid(chunk_ingate)\n",
        "        cty = torch.tanh(chunk_cellgate)\n",
        "        ox = torch.sigmoid(chunk_outgate)\n",
        "\n",
        "        out_cy = (cx * fx) + (ix * cty)\n",
        "\n",
        "        out_hy = torch.tanh(out_cy) * ox\n",
        "\n",
        "        return out_hy, (out_hy, out_cy) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flFSEYt1H6L3"
      },
      "source": [
        "class LSTMLayer(nn.Module):\n",
        "    def __init__(self,*cell_args):\n",
        "        super(LSTMLayer, self).__init__()\n",
        "        self.cell = LSTMCell(*cell_args)\n",
        "\n",
        "    def forward(self, x, state, length_x=None):\n",
        "        inputs = x.unbind(0)\n",
        "        assert (length_x is None) or torch.all(length_x == length_x.sort(descending=True)[0])\n",
        "        outputs = [] \n",
        "        out_hidden_state = []\n",
        "        out_cell_state = []\n",
        "        for i in range(len(inputs)):\n",
        "            out, state = self.cell(inputs[i] , state)\n",
        "            outputs += [out] \n",
        "            if length_x is not None:\n",
        "                if torch.any(i+1 == length_x):\n",
        "                    out_hidden_state = [state[0][i+1==length_x]] + out_hidden_state\n",
        "                    out_cell_state = [state[1][i+1==length_x]] + out_cell_state\n",
        "        if length_x is not None:\n",
        "            state = (torch.cat(out_hidden_state, dim=0), torch.cat(out_cell_state, dim=0))\n",
        "        return torch.stack(outputs), state \n",
        "    \n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, ninp, nhid, num_layers, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.layers = []\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.layers.append(LSTMLayer(ninp, nhid))\n",
        "            else:\n",
        "                self.layers.append(LSTMLayer(nhid, nhid)) \n",
        "        self.layers = nn.ModuleList(self.layers) \n",
        "\n",
        "    def forward(self, x, states, length_x=None):\n",
        "          output_states = []\n",
        "          \n",
        "          input = x\n",
        "          for i in range(len(states)):\n",
        "            output_tensor, output_state = self.layers[i](input, states[i], length_x)\n",
        "            output_states.append(output_state)\n",
        "            \n",
        "            input = self.dropout(output_tensor)\n",
        "\n",
        "          return output_tensor, output_states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPY0DTXHH9gI"
      },
      "source": [
        "class LSTMModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModule, self).__init__()\n",
        "        ninp = args.ninp\n",
        "        nhid = args.nhid\n",
        "        nlayers = args.nlayers\n",
        "        dropout = args.dropout\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = LSTM(ninp, nhid, nlayers, dropout)\n",
        "        \n",
        "    def forward(self, x, states, length_x=None):\n",
        "        input = self.dropout(x)\n",
        "\n",
        "        return self.lstm(input, states, length_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrdxLgy9H_WS"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.LSTM_LtoR = LSTMModule()\n",
        "        self.LSTM_RtoL = LSTMModule()\n",
        "        self.ff1 = nn.Linear(args.nhid, args.nhid)\n",
        "        \n",
        "        self.ff2 = nn.Linear(args.nhid, trg_ntoken)\n",
        "\n",
        "        self.seq = nn.Sequential (nn.Linear(args.nhid*2, args.nhid), \n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(0.2),\n",
        "                                  nn.Linear(args.nhid, trg_ntoken),\n",
        "                                  nn.Softmax(dim = -1))\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "        self.embed = nn.Embedding(num_embeddings = vocab_size, embedding_dim = vector_size)\n",
        "        self.embed.weight = nn.Parameter(torch.tensor(emb_matrix, dtype=torch.float32))\n",
        "    \n",
        "    def forward(self, x, y, length, max_len=None, teacher_forcing=True):\n",
        "        \n",
        "        B = int(x.shape[1])\n",
        "        x = self.embed(x)\n",
        "        zero_tensor = torch.zeros(B, args.nhid).to(device)\n",
        "        init_states = [(zero_tensor, zero_tensor)]*args.nlayers\n",
        "\n",
        "        reverse_x = torch.flip(x, [1])\n",
        "\n",
        "        output1, _ = self.LSTM_LtoR(x, init_states, length)\n",
        "        output2, _ = self.LSTM_RtoL(reverse_x, init_states, length)\n",
        "\n",
        "        output2 = torch.flip(output2, [1])\n",
        "\n",
        "        output = torch.cat((output1, output2), dim = -1)\n",
        "\n",
        "        output = output.transpose(0, 1)\n",
        "        output = self.seq(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Je_7kRIDOK"
      },
      "source": [
        "def sort_batch(x, y):\n",
        "    lengths = (x!=pad_id).long().sum(0)\n",
        "    length, idx = lengths.sort(dim = 0, descending= True)\n",
        "    x = torch.index_select(x, 1, idx)\n",
        "    y = torch.index_select(y, 1, idx)\n",
        "    return x, y, length\n",
        "\n",
        "def save_model(model, mode=\"last\"):\n",
        "    torch.save(model.state_dict(),  result_dir / f'{type(model).__name__}_{mode}.ckpt')\n",
        "    \n",
        "def load_model(model, mode=\"last\"):\n",
        "    if os.path.exists(result_dir / f'{type(model).__name__}_{mode}.ckpt'):\n",
        "        model.load_state_dict(torch.load(result_dir / f'{type(model).__name__}_{mode}.ckpt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCeoNgKMIFaE"
      },
      "source": [
        "loss_weight = torch.FloatTensor ([0,1,13.8,13.6,30,0]).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_id, weight = loss_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELaT6QGnIGNW"
      },
      "source": [
        "def run_epoch(epoch, model, optimizer, is_train = True, data_loader = None):\n",
        "\n",
        "    total_loss = 0\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    \n",
        "    if data_loader is None:\n",
        "        data_loader = train_dataloader if is_train else valid_dataloader\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    for batch in data_loader:\n",
        "\n",
        "        x, y = batch['input'].to(device), batch['punc'].to(device)\n",
        "        \n",
        "        x, y = x.transpose(0,1), y.transpose(0,1)\n",
        "        x, y, length = sort_batch(x, y)\n",
        "        target = y.transpose(0,1)\n",
        "\n",
        "        pred = model(x, y, length)\n",
        "        loss = criterion(pred.reshape(-1, trg_ntoken), target.reshape(-1))\n",
        "        n_targets = (target != pad_id).long().sum().item() \n",
        "        n_total += n_targets \n",
        "        n_correct += (pred.argmax(-1) == target)[target != pad_id].long().sum().item()\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "            optimizer.step()\n",
        "           \n",
        "            \n",
        "        total_loss += loss.item() * n_targets\n",
        "    total_loss /= n_total\n",
        "    print(\"Epoch\", epoch, 'Train' if is_train else 'Valid', \n",
        "          \"Loss\", np.mean(total_loss), \n",
        "          \"Acc\", n_correct / n_total)\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkvY_UAhIIMo"
      },
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                    factor = 0.25, patience = 1, threshold = 0.0001, threshold_mode = 'rel',\n",
        "                                                    cooldown = 0, min_lr = 0, eps = 1e-08, verbose = False)\n",
        "    best_val_loss = np.inf\n",
        "    #for epoch in tq.tqdm(range(args.epochs)):\n",
        "    for epoch in tq.tqdm(range(args.epochs)):\n",
        "        # train one epoch\n",
        "        run_epoch(epoch, model, optimizer, is_train = True)\n",
        "\n",
        "        # calculate validation loss and save\n",
        "        with torch.no_grad():\n",
        "            val_loss = run_epoch(epoch, model, None, is_train = False)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            save_model(model, 'best')\n",
        "\n",
        "        save_model(model)\n",
        "        scheduler.step(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts3Y-PDOIKFO"
      },
      "source": [
        "model = BiLSTM().to(device)\n",
        "run_experiment(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UC7uvIbxrmo"
      },
      "source": [
        "def reverse_dict(src_dict):\n",
        "  rev_dict = dict()\n",
        "  for word in src_dict:\n",
        "    rev_dict[src_dict[word]] = word\n",
        "  return rev_dict\n",
        "\n",
        "rev_word_dict = reverse_dict(word_dict)\n",
        "rev_punc_dict = {0: ' ', 1: ' ', 2: '. ', 3:', ', 4: '? ', 5: ' '}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcIzRFtQlvnI"
      },
      "source": [
        "\"\"\"\n",
        "If you are running the code from scratch, \n",
        "you should also run this code for applying the model.\n",
        "With the embedding matrix, download this to your local computer, in a appropriate directory.\n",
        "\"\"\"\n",
        "with open(root + '/input/rev_dict', 'wb') as file:\n",
        "  pickle.dump(rev_word_dict, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4xtQ_HjxjNQ"
      },
      "source": [
        "def run_test(model, mode='best'):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        load_model(model, mode)\n",
        "\n",
        "        src_list = []\n",
        "        gt_list = []\n",
        "        pred_list = []\n",
        "\n",
        "        total_loss = 0\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "\n",
        "        confusion_matrix = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0] ]\n",
        "        total_counts = [0,0,0,0]\n",
        "\n",
        "        percent_matrix = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0] ]\n",
        "\n",
        "        for batch in test_dataloader:\n",
        "            print_string = ''\n",
        "            x, y = batch['input'].to(device), batch['punc'].to(device)\n",
        "\n",
        "            x, y = x.transpose(0,1), y.transpose(0,1)\n",
        "            x, y, length = sort_batch(x, y)\n",
        "            target = y.transpose(0,1)\n",
        "            source = x.transpose(0,1)\n",
        "\n",
        "            pred = model(x, y, length)\n",
        "            loss = criterion(pred.reshape(-1, trg_ntoken), target.reshape(-1))\n",
        "            n_targets = (target!=pad_id).long().sum().item() \n",
        "            n_total += n_targets \n",
        "            prediction = pred.argmax(-1)\n",
        "            n_correct += (pred.argmax(-1)==target)[target!=pad_id].long().sum().item()\n",
        "\n",
        "            for x_, y_, pred_ in zip(x, target, pred.argmax(-1)):\n",
        "                src_list.append(x_)\n",
        "                gt_list.append(y_)\n",
        "                pred_list.append(pred_)\n",
        "\n",
        "            total_loss += loss.item() * n_targets\n",
        "\n",
        "            for i in range(32):\n",
        "              for j in range(100):\n",
        "                try:\n",
        "                  if 0<target[i][j]<5:\n",
        "                    total_counts[target[i][j]-1] += 1\n",
        "                    if 0<prediction[i][j]<5:\n",
        "                      confusion_matrix[target[i][j]-1][prediction[i][j]-1] += 1\n",
        "                except: continue\n",
        "           \n",
        "            # code for printing out the result.\n",
        "            # comment out if not neccesary\n",
        "            for i in range(32):\n",
        "              target_sent = ''\n",
        "              pred_sent = ''\n",
        "              for j in range(100):\n",
        "                try:\n",
        "                  target_sent += rev_word_dict[int(source[i][j])]\n",
        "                  pred_sent += rev_word_dict[int(source[i][j])]\n",
        "                  target_sent += rev_punc_dict[int(target[i,j])]\n",
        "                  pred_sent += rev_punc_dict[int(prediction[i,j])]\n",
        "                except: continue\n",
        "              print(\"<<example>>\")\n",
        "              print(target_sent)\n",
        "              print(pred_sent)\n",
        "\n",
        "            \n",
        "        for i in range(4):\n",
        "          for j in range(4):\n",
        "            percent_matrix[i][j] = confusion_matrix[i][j] / total_counts[i]\n",
        "            \n",
        "\n",
        "        total_loss /= n_total\n",
        "\n",
        "        print('Test', \n",
        "                \"Loss\", np.mean(total_loss), \n",
        "                \"Acc\", n_correct / n_total)\n",
        "        \n",
        "        for i in range(10):\n",
        "            print(f\"--------- Translation Example {i+1} ---------\")\n",
        "            print(''.join(map(str, gt_list[i].tolist())))\n",
        "            print(''.join(map(str, pred_list[i].tolist())))\n",
        "            print()\n",
        "        print()\n",
        "        print()\n",
        "        \n",
        "        print(total_counts)\n",
        "        print(confusion_matrix)\n",
        "        print(percent_matrix)\n",
        "\n",
        "        return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtL4wnZ_xz2k"
      },
      "source": [
        "model = BiLSTM().to(device)\n",
        "run_test(model, mode = 'best')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}